## Big Data Coursework 

Author: Yuyan Wu

#### Introduction

This course covers a variety of topics and tools in big data. Most of the topics are about the Hadoop ecosystem including Spark, however select databases outside of Hadoop will also be considered.

The coursework demonstrates an understanding of distributed computing and databases, implementing algorithms in MapReduce, use of Hive, use of NoSQL database Hbase, and use of Spark.

Below is the Overview for each assignment.

#### Overviews of Problem Sets

##### Assignment 1

This problem set tests the ability to create MapReduce jobs to handle tasks including extracting data, cleaning data, calculating data summaries such as count and standard deviation, and sorting data for Big Data in Hadoop.

##### Assignment 2

This problem set tests the ability to perform EDA, build model pipeline in SparkSQL and plain Spark (Spark RDDs), and run the jobs in Hadoop.

##### Assignment 3

This problem set must be completed using Amazon Web Services. It requires building a classification model and creating a Spark EC2 cluster or using EMR to execute the task.
##### Assignment 4

This problem set tests the ability to create Hbase databases and query data from the databases.
